[
{
	"uri": "//localhost:1313/1-introduce/1.1-elasticcache/",
	"title": "ElasticCache",
	"tags": [],
	"description": "",
	"content": "Amazon ElastiCache makes it easy to set up, manage, and scale a distributed caching environment in the AWS Cloud. It provides a high-performance, scalable, and cost-effective in-memory cache, while eliminating the complexity associated with deploying and managing a distributed caching environment.\nElastiCache supports two open-source in-memory caching engines: Redis and Memcached.\nRedis, short for Remote Dictionary Server, is a fast, open-source data structure store. It is commonly used as a distributed in-memory data store that is used as a database, cache, streaming engine, and message broker. Redis supports a variety of abstract data structures, such as strings, lists, maps, sets, sorted sets, HyperLogLog, bitmaps, streams, and spatial indices. Memcached is an intuitive, high-performance in-memory data store. It provides a mature, scalable, open-source solution for delivering sub-millisecond response times, making it useful as a cache or a non-durable session store. ElastiCache is a fully managed in-memory caching service that supports real-time use cases that require extremely fast performance and high throughput. ElastiCache is often used as a cache to increase application or database performance. It can also serve as the primary data store for use cases that do not require durability, such as session stores, gaming leaderboards, streaming, and API rate limiting.\nWhat problems does ElastiCache solve? Using ElastiCache, you can streamline how you deploy, operate, and scale in the cloud. With traditional databases, you have to manage the infrastructure and underlying upgrades, patching, cluster management, backups, and production workloads. Fully managed database services automate these tasks. Here are some ways ElastiCache can help:\nProvide API-compliant Redis and Memcached engines with any open source application that uses OSS Redis or Memcached Scale your compute and memory resources vertically or horizontally in minutes Scale your read/write capacity based on changing business needs Provide high levels of security and support for Amazon Virtual Private Cloud (Amazon VPC), Transport Layer Security (TLS), encryption, and qualify for multiple compliance certifications Provide continuous monitoring and automatic failover The goal of ElastiCache is to reduce the additional complexity of managing your in-memory caching system for Redis and Memcached engines. Developers can continue to use the same Redis and Memcached application code, drivers, and tools to run, manage, and scale their workloads on ElastiCache. Developers and administrators can rely on managed services to handle the heavy lifting, focusing on application development to add value to their customers.\nHow is ElastiCache used to build cloud solutions? ElastiCache stores data in the server\u0026rsquo;s main memory (DRAM) for fast access. ElastiCache is often used as a cache in front of a backend primary database such as Amazon Relational Database Service (Amazon RDS). Since data stored in DRAM can be accessed much faster than disk-based systems, ElastiCache can provide significant performance benefits when placed in front of the database.\nElastiCache is an in-memory only service designed to provide blazing fast performance at the expense of durability. It can serve temporary data reads/writes at microsecond latency, which is desirable for real-time applications.\nThe following diagram shows an example of how when a client sends a request to an application, it first tries to retrieve the corresponding data from ElastiCache. If the request is successful, it is called a cache hit. If it is unsuccessful, it is called a cache miss. In case of a cache miss, the request is forwarded to the real data source (RDS MySQL in this case) and the corresponding data is retrieved. The data is then written to the cache before the response is sent back to the client.\nExample of how ElastiCache handles client requests to the application\n"
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Among the many ways that computers process data, one of the most common is read-only data that needs to be presented quickly and to a large number of users, such as music or videos that are streamed around the world. This type of data is rarely updated or deleted, but it is large in volume and demand can fluctuate significantly (think of a viral video or song). Because the need for this type of access is becoming more common, Amazon Web Services (AWS) provides tools to handle it. These tools are essentially tools that can retrieve data quickly and distribute it across multiple servers to meet peaks and troughs in demand—and do so in a cost-effective way, charging only for usage.\nApplications and websites often provide a wide range of data and services to users. Within this large data set, there is often a smaller subset of data that is requested and accessed more frequently. This could be front-page data that is shown to every visitor (think Amazon’s top 10 products of the day), or it could be a recently released piece of media that is experiencing a spike in popularity (a new song released on Spotify). Other applications run extremely memory-intensive processes and may experience performance issues on slower storage.\nIn this workshop, we’ll take a deeper look at Amazon ElastiCache and Elastic Load Balancing?, exploring how it works, the benefits, and how to deploy it to optimize your application performance.\nWhat you will learn What is ElasticCache ? What is Elastic Load Balancing ? Pricing Types of ELBs in AWS "
},
{
	"uri": "//localhost:1313/2-lab1/2.1-launch_the_first_ec2_instance/",
	"title": "Launch the first EC2 instance",
	"tags": [],
	"description": "",
	"content": "Đầu tiên hãy tạo 1 EC2 instance In the search box to the right of Services, search for and select EC2 to open the EC2 console Select the Launch Instance button in the middle of the page, then select Launch Instance from the drop-down menu. Next, enter a name and select Application and OS Images as Amazon Linux to use the free tier. Select Instance type as t2.micro (free tier) and key pair as vockey In the Network settings section, select Edit.\nUnder Subnet, select the existing subnet in Availability Zone us-east-1a.\nFor Security group name enter Web Server security group\nFor Description enter Security group for my web server\nIn the Inbound security groups rules section, select Remove to delete the default rule.\nSelect Add security group rule to configure a new rule as shown below\nType : HTTP Source type : Anywhere After this step, it will create a new Security group. If you want to choose security according to your wishes, choose exiting security group!\nIn the Configure storage table, keep the default storage configuration.\nConfigure the Advance details section to insert a sample script to test EC2\nExpand the Advance details section Scroll down to the bottom of the User data section and enter the sample cli script as below #!/bin/bash\ryum update -y\ryum -y install httpd\rsystemctl enable httpd\rsystemctl start httpd\recho \u0026#39;\u0026lt;html\u0026gt;\u0026lt;h1\u0026gt;Hello World! This is server 1.\u0026lt;/h1\u0026gt;\u0026lt;/html\u0026gt;\u0026#39; \u0026gt; /var/www/html/index.html This script does the following:\nUpdate the server Install the Apache web server (httpd) Configure the web server to start automatically on boot Start the web server Create a simple web page Double check again and select Launch instance in Summary section. Next after Lauch log Succeeded all select Instances Please wait a moment and wait for its status to be ready all Visit your EC2 instance\u0026rsquo;s website Copy Ipv4 string and access: http://\u0026lt;ip của bạn\u0026gt; "
},
{
	"uri": "//localhost:1313/",
	"title": "Load Balancer",
	"tags": [],
	"description": "",
	"content": "Overview In this post, we will learn about Elastic Load Balancing on AWS\nContents included Introduction\nLab 1: Initializing EC2 Instance\nLab 2: Initializing Load balancer\nTesting and cleanup\nContent Introduction Create EC2 instance for load balancer Initialize load balancer Test clean up "
},
{
	"uri": "//localhost:1313/1-introduce/1.2-elastic_load_balancing/",
	"title": "Elastic Load Balancing",
	"tags": [],
	"description": "",
	"content": "Other applications run extremely memory-intensive processes and may experience performance issues on slower storage.\nFor this type of highly requested or memory-intensive data, a data caching service like ElastiCache can help ensure that data can be accessed and processed extremely quickly. It works by storing data in ultra-fast memory, but temporarily, faster than disk storage. The trade-off is that fast storage has less storage capacity and does not store data permanently.\nMany companies use ElastiCache to build real-time applications, accelerate e-commerce, and cache their websites. Use cases: real-time transactions, chat, BI and analytics, session stores, gaming leaderboards, and caching.\nHeavy traffic can take down applications and websites if the server cannot handle the load. This is why AWS has ELB, which can detect when there are too many requests and automatically redirect traffic to new servers to maintain speed and stability.\nElastic Load Balancing automatically distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more Availability Zones. It monitors the health of registered targets and routes traffic only to healthy targets. Elastic Load Balancing automatically adjusts your load balancer capacity in response to changes in incoming traffic.\nBenefits of Load Balancing Elastic Load Balancing automatically distributes incoming application traffic across multiple targets, such as Amazon Elastic Computing Cloud (Amazon EC2) instances, containers, IP addresses, and AWS Lambda functions.\nIf traffic to a website suddenly spikes, that traffic can be routed to other EC2 instances (or other instance types such as Lambda instances) that have been pre-set up for this purpose. This load balancing prevents a single server from being overloaded by increased traffic.\nKey benefits of ELB: Increased availability: Traffic distribution: ELB distributes traffic to multiple instances, reducing the risk of one instance failing. If an instance fails, ELB automatically redirects requests to the remaining instances.\nResilience: ELB continuously monitors the health of instances and automatically removes inactive ones and adds new ones as needed.\nImproved performance: Load distribution: ELB helps distribute workload evenly across instances, preventing one instance from becoming overloaded.\nReduce Response Time: By distributing traffic, ELB helps reduce application response time, providing a better user experience.\nIncrease Scalability: Automatic Scaling: ELB can automatically adjust the size of the instance cluster to meet the changing needs of the application. As traffic increases, ELB will automatically add new instances to the cluster and vice versa. Security: SSL/TLS Connection: ELB supports SSL/TLS connection to secure data transmitted between users and applications.\nCertificate Management: ELB helps you easily manage SSL/TLS certificates.\nAdvanced Features: Path-Based Load Balancing: ELB can distribute traffic based on URL paths, helping to optimize the use of resources.\nCookie-based load balancing: ELB can maintain user sessions using cookies, ensuring that requests from a particular user are always sent to the same instance.\nIntegration with other AWS services: ELB can easily integrate with other AWS services such as Auto Scaling, CloudWatch, and Route 53.\n"
},
{
	"uri": "//localhost:1313/2-lab1/",
	"title": "Lab 1: Create EC2 instance",
	"tags": [],
	"description": "",
	"content": "Now we will start the lab by creating a simulation of Three computers accessing content in the AWS Cloud. A load balancer will split this access between Availability Zone A and Availability Zone B. Each Availability Zone has three EC2 instances, but one instance in Availability Zone A is down.\nStart by creating 2 EC2 Instances in 2 different regions !\n"
},
{
	"uri": "//localhost:1313/2-lab1/2.2-launch_second_ec2_instance/",
	"title": "Launch a second EC2 instance",
	"tags": [],
	"description": "",
	"content": "Now we will start the lab by creating a simulation of Three computers accessing content in the AWS Cloud. A load balancer will split this access between Availability Zone A and Availability Zone B. Each Availability Zone has three EC2 instances, but one instance in Availability Zone A is down.\nStart by creating 2 EC2 Instances in 2 different regions !\n"
},
{
	"uri": "//localhost:1313/1-introduce/1.3-pricing/",
	"title": "Pricing",
	"tags": [],
	"description": "",
	"content": "Elastic Load Balancing offers four load balancers, all of which provide high availability, auto-scaling, and robust security for your applications: Application Load Balancer, Network Load Balancer, Gateway Load Balancer, and Classic Load Balancer. You pay only for what you use with these services.\nApplication Load Balancer You are charged for each hour or partial hour that the Application Load Balancer is running and the number of Load Balancer Capacity Units (LCUs) used per hour.\nNetwork Load Balancer You are charged for each hour or partial hour that the Network Load Balancer is running and the number of Network Load Balancer Capacity Units (NLCUs) used per hour.\nGateway Load Balancer You are charged for each hour or partial hour that the Gateway Load Balancer is running and the number of Gateway Load Balancer Capacity Units (GLCUs) used by the Gateway Load Balancer per hour. The Gateway Load Balancer uses Gateway Load Balancer Endpoints (GWLBEs). These are new VPC Endpoint types powered by AWS PrivateLink technology that simplify how applications securely exchange traffic using GWLB across VPC edges. GWLBEs are priced and billed separately.\nClassic Load Balancer You are charged for each hour or partial hour that the Classic Load Balancer is running and for each GB of data transferred through your load balancer.\nAWS Free Trier After I researched, ELBs are included in AWS\u0026rsquo;s free trier program for new accounts. Upon sign-up, new AWS customers receive 750 shared hours per month for Classic Load Balancer and Application Load Balancer; 15 GB of data processing for Classic Load Balancer and 15 LCUs for Application Load Balancer.\nFor more details on the cost of ELB visit Network and Application Traffic Distribution - Elastic Load Balancing Pricing - AWS (amazon.com)\n"
},
{
	"uri": "//localhost:1313/1-introduce/1.4-types_of_elbs_in_aws/",
	"title": "Types of ELBs",
	"tags": [],
	"description": "",
	"content": "Heavy traffic can shut down applications and websites if the server cannot handle the load. This is why AWS has ELBs, which can detect when there are too many requests and automatically redirect traffic to new servers to maintain speed and stability. There are three types of ELBs in AWS.\nApplication Load Balancers: Application Load Balancers are best suited for load balancing Hypertext Transfer Protocol (HTTP) and Secure HTTP (HTTPS) traffic, and provide advanced request routing targeted at delivering modern application architectures, including microservices and containers. Operating at the individual request level (Layer 7), Application Load Balancers route traffic to targets in the Amazon Virtual Private Cloud (Amazon VPC) based on the content of the request. Application Load Balancing is performed based on the content of a Uniform Resource Locator (URL). For example, if the URL ends in /main, the request will be routed to one instance; if the URL ends in blog/, it will be routed to another instance if the Application Load Balancer definition work has been done beforehand to do so.\nNetwork Load Balancer: The Network Load Balancer is best suited for load balancing Transmission Control Protocol (TCP), User Datagram Protocol (UDP), and Transport Layer Security (TLS) traffic when extreme performance is required. Operating at the connection level (Layer 4), the Network Load Balancer routes traffic to targets within the Amazon VPC and is capable of handling millions of requests per second while maintaining extremely low latency. The Network Load Balancer is also optimized to handle bursty and unstable traffic patterns.\nBecause of the increased speed that can be achieved at the connection layer, the Network Load Balancer load balancer type is preferred when trying to avoid higher network traffic. For example, to avoid delays when interest in a site spreads widely, you should choose to use Network Load Balancer.\nClassic Load Balancer: Classic Load Balancer provides basic load balancing across multiple EC2 instances and operates at the request and connection level. Classic Load Balancer is for applications built on the EC2-Classic network.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]